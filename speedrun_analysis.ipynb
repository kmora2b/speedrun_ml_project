{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmora2b/speedrun_ml_project/blob/main/speedrun_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20956c18",
      "metadata": {
        "id": "20956c18"
      },
      "source": [
        "# Predicting Speedrun World Record Times\n",
        "\n",
        "This notebook aims to predict world record times for speedrunning based on features such as the game, category, and platform. It uses multiple regression models, including Linear Regression, Random Forest, and Gradient Boosting, with a focus on improving model performance through hyperparameter tuning, regularization, and cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ac5886ed",
      "metadata": {
        "id": "ac5886ed"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from scipy.stats import normaltest, skew\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "487103ae",
      "metadata": {
        "id": "487103ae"
      },
      "source": [
        "## Load and Explore the Dataset\n",
        "\n",
        "The dataset contains speedrunning records for various games, including features such as game name, category, platform, and the world record time.\n",
        "The goal is to predict the world record time for a given game and category based on these features.\n",
        "\n",
        "###Data Source\n",
        "The dataset is publicly available on Kaggle and was created by Matheus Turatti.\n",
        "\n",
        "###Citation: Turatti, M. (n.d.). Game Speedrun Records [Data set]. Kaggle. https://www.kaggle.com/datasets/matheusturatti/game-speedrun-records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "454d7ad3",
      "metadata": {
        "id": "454d7ad3"
      },
      "outputs": [],
      "source": [
        "\n",
        "url = \"https://www.kaggleusercontent.com/datasets/matheusturatti/game-speedrun-records\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "print(\"Dataset Overview:\")\n",
        "print(data.info())\n",
        "print(data.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2219dbd5",
      "metadata": {
        "id": "2219dbd5"
      },
      "source": [
        "## Data Cleaning\n",
        "\n",
        "Missing values are dropped to ensure a clean dataset for training the models. The categorical features are one-hot encoded for compatibility with machine learning algorithms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bdc490b",
      "metadata": {
        "id": "6bdc490b"
      },
      "outputs": [],
      "source": [
        "\n",
        "cleaned_data = data.dropna()\n",
        "categorical_features = ['game', 'category', 'platform']\n",
        "data_encoded = pd.get_dummies(cleaned_data, columns=categorical_features, drop_first=True)\n",
        "X = data_encoded.drop('time', axis=1)\n",
        "y = data_encoded['time']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99526919",
      "metadata": {
        "id": "99526919"
      },
      "source": [
        "## Split Data for Training and Testing\n",
        "\n",
        "The dataset is split into training and testing sets (80%-20%) to evaluate the model's performance on unseen data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bbe5ec3",
      "metadata": {
        "id": "0bbe5ec3"
      },
      "outputs": [],
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0e570b1",
      "metadata": {
        "id": "a0e570b1"
      },
      "source": [
        "## Train Multiple Models\n",
        "\n",
        "Linear Regression, Ridge Regression, Lasso Regression, Random Forest, and Gradient Boosting models are trained and their performance is compared using RMSE and R-squared metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d55c5c9e",
      "metadata": {
        "id": "d55c5c9e"
      },
      "outputs": [],
      "source": [
        "\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Ridge Regression': Ridge(),\n",
        "    'Lasso Regression': Lasso(),\n",
        "    'Random Forest': RandomForestRegressor(random_state=42),\n",
        "    'Gradient Boosting': GradientBoostingRegressor(random_state=42)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
        "    r2 = r2_score(y_test, predictions)\n",
        "    results[name] = {'RMSE': rmse, 'R^2': r2}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df9da963",
      "metadata": {
        "id": "df9da963"
      },
      "source": [
        "## Hyperparameter Tuning and Cross-Validation\n",
        "\n",
        "Random Forest is tuned using grid search for optimal parameters. Gradient Boosting is evaluated using cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6d8b347",
      "metadata": {
        "id": "b6d8b347"
      },
      "outputs": [],
      "source": [
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "rf_grid_search = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "rf_grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_rf_model = rf_grid_search.best_estimator_\n",
        "rf_predictions = best_rf_model.predict(X_test)\n",
        "rf_rmse = np.sqrt(mean_squared_error(y_test, rf_predictions))\n",
        "rf_r2 = r2_score(y_test, rf_predictions)\n",
        "\n",
        "gbr_model = GradientBoostingRegressor(random_state=42)\n",
        "cross_val_scores = cross_val_score(gbr_model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
        "mean_cv_rmse = np.sqrt(-cross_val_scores.mean())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56298580",
      "metadata": {
        "id": "56298580"
      },
      "source": [
        "## Results and Performance Comparison\n",
        "\n",
        "The RMSE and R-squared metrics for each model are compared. The performance of the tuned Random Forest model and Gradient Boosting is highlighted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b123c6f",
      "metadata": {
        "id": "9b123c6f"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"Model Results:\")\n",
        "for name, metrics in results.items():\n",
        "    print(f\"{name}: RMSE = {metrics['RMSE']:.2f}, R^2 = {metrics['R^2']:.2f}\")\n",
        "\n",
        "print(\"Best Random Forest Model After Tuning:\")\n",
        "print(f\"RMSE: {rf_rmse:.2f}, R^2: {rf_r2:.2f}\")\n",
        "\n",
        "print(\"Gradient Boosting Cross-Validation Mean RMSE:\")\n",
        "print(f\"Mean CV RMSE: {mean_cv_rmse:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bb59314",
      "metadata": {
        "id": "5bb59314"
      },
      "source": [
        "## Visualize Model Performance\n",
        "\n",
        "A bar plot compares the RMSE values across different models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d6bd1bb",
      "metadata": {
        "id": "0d6bd1bb"
      },
      "outputs": [],
      "source": [
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "model_names = list(results.keys()) + [\"Tuned Random Forest\", \"Gradient Boosting CV\"]\n",
        "rmse_values = [metrics['RMSE'] for metrics in results.values()] + [rf_rmse, mean_cv_rmse]\n",
        "\n",
        "sns.barplot(x=rmse_values, y=model_names, orient='h')\n",
        "plt.title(\"Model RMSE Comparison\")\n",
        "plt.xlabel(\"RMSE\")\n",
        "plt.ylabel(\"Model\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fe0c81a",
      "metadata": {
        "id": "8fe0c81a"
      },
      "source": [
        "## Feature Importance from Best Random Forest Model\n",
        "\n",
        "The top 10 most important features are visualized for the best Random Forest model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a113a41c",
      "metadata": {
        "id": "a113a41c"
      },
      "outputs": [],
      "source": [
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': best_rf_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Importance', y='Feature', data=feature_importance.head(10))\n",
        "plt.title(\"Top 10 Feature Importances - Best Random Forest\")\n",
        "plt.xlabel(\"Importance\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81b4f5bd",
      "metadata": {
        "id": "81b4f5bd"
      },
      "source": [
        "## Discussion and Suggestions for Improvement\n",
        "\n",
        "1. **Learning and Takeaways:**\n",
        "   - Random Forest achieved the best performance.\n",
        "   - Gradient Boosting also performed well with cross-validation.\n",
        "2. **Challenges:**\n",
        "   - Linear Regression struggled due to potential multicollinearity.\n",
        "   - Lasso Regression may have overly penalized features.\n",
        "3. **Suggestions for Improvement:**\n",
        "   - Experiment with stacking ensemble techniques.\n",
        "   - Perform feature selection or dimensionality reduction (e.g., PCA).\n",
        "   - Include additional features such as player statistics or game metadata."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}